{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import sklearn as sk\n",
    "\n",
    "sys.path.append('C:\\\\Users\\\\dalun\\\\PycharmProjects\\\\Thesiss')\n",
    "\n",
    "import qtLibrary.libquanttree as qt\n",
    "import main_code.neuralNetworks as nn\n",
    "import pickle as pk\n",
    "from main_code.auxiliary_project_functions import create_bins_combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 9)\n",
      "0.16947259348224802\n",
      "0.06604053528243103\n",
      "0.07034939431321958\n",
      "0.08242142618464099\n"
     ]
    }
   ],
   "source": [
    "#Create dataframe from saved thresholds\n",
    "\n",
    "frame_1N = pd.read_csv('File_N_and_thr_0_01')\n",
    "frame_5N = pd.read_csv('File_N_and_thr_0_5')\n",
    "frame_1A = pd.read_csv('Asymptotic_0._1')\n",
    "frame_5A = pd.read_csv('Asymptotic_0_5')\n",
    "\n",
    "frames = [frame_1N, frame_1A, frame_5N, frame_5A]\n",
    "\n",
    "for frame in frames:\n",
    "    frame = frame.iloc[:, 1:]\n",
    "\n",
    "# frame_1N = frame_1N.iloc[:,1:]\n",
    "# frame_1A = frame_1A.iloc[:,1:]\n",
    "# frame_5N = frame_5N.iloc[:,1:]\n",
    "# frame_5A = frame_5A.iloc[:,1:]\n",
    "    \n",
    "\n",
    "training_1N = frame_1N.iloc[:, np.r_[:frame.shape[1] - 1, -1]]\n",
    "print(training_1N.shape)\n",
    "thresholds_1N = frame_1N.iloc[:,-2]\n",
    "\n",
    "training_5N = frame_5N.iloc[:, np.r_[:frame.shape[1] - 1, -1]]\n",
    "thresholds_5N = frame_5N.iloc[:,-2]\n",
    "\n",
    "training_1A = frame_1A.iloc[:, :-1]\n",
    "thresholds_1A = frame_1A.iloc[:,-1]\n",
    "\n",
    "training_5A = frame_5A.iloc[:, :-1]\n",
    "thresholds_5A = frame_5A.iloc[:,-1]\n",
    "    \n",
    "for threshold in [thresholds_1N, thresholds_5N, thresholds_1A, thresholds_5A]:\n",
    "    print(np.var(threshold))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 10\n",
      "0.4621412471968213\n",
      "0.18851229703268557\n",
      "6.113667254037392e-05\n",
      "0.0002245731715331267\n"
     ]
    }
   ],
   "source": [
    "#Train networks\n",
    "\n",
    "nodes = 10\n",
    "print('nodes: ' + str(nodes))\n",
    "easy_cor_1N = np.array(training_1N) #.iloc[:,-3:]\n",
    "easy_cor_5N = np.array(training_5N) #.iloc[:,-3:]\n",
    "easy_cor_1A = np.array(training_1A) #.iloc[:,-3:]\n",
    "easy_cor_5A = np.array(training_5A) #.iloc[:,-3:]\n",
    "\n",
    "\n",
    "easy_cor = [easy_cor_1N, easy_cor_5N, easy_cor_1A, easy_cor_5A]\n",
    "thresholds = [thresholds_1N, thresholds_5N, thresholds_1A, thresholds_5N]\n",
    "\n",
    "learner_1N = sk.neural_network.MLPRegressor(early_stopping=True, hidden_layer_sizes=nodes, solver='lbfgs', learning_rate='constant', max_iter=10000, n_iter_no_change=40, verbose=False, random_state=True, alpha = 0)\n",
    "learner_5N = sk.neural_network.MLPRegressor(early_stopping=True, hidden_layer_sizes=nodes, solver='lbfgs', learning_rate='constant', max_iter=10000, n_iter_no_change=40, verbose=False, random_state=True, alpha = 0)\n",
    "learner_1A = sk.neural_network.MLPRegressor(early_stopping=True, hidden_layer_sizes=nodes, solver='lbfgs', learning_rate='constant', max_iter=10000, n_iter_no_change=40, verbose=False, random_state=True, alpha = 0)\n",
    "learner_5A = sk.neural_network.MLPRegressor(early_stopping=True, hidden_layer_sizes=nodes, solver='lbfgs', learning_rate='constant', max_iter=10000, n_iter_no_change=40, verbose=False, random_state=True, alpha = 0)\n",
    "\n",
    "learners = [learner_1N, learner_5N, learner_1A, learner_5A]\n",
    "\n",
    "for index in range(len(learners)):\n",
    "    learners[index].fit(easy_cor[index], thresholds[index])\n",
    "    print(learners[index].score(easy_cor[index], thresholds[index]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = [0.5]\n",
      "       trhesholds  thresholds2  regressions  inner differences  differences\n",
      "count   10.000000    10.000000    10.000000          10.000000    10.000000\n",
      "mean     5.895229     5.917697     5.780930           0.044509     0.229405\n",
      "std      0.389052     0.411878     0.051681           0.053593     0.279231\n",
      "min      5.386164     5.376485     5.684557           0.004072     0.014776\n",
      "25%      5.699690     5.701046     5.755112           0.008843     0.064994\n",
      "50%      5.791317     5.881577     5.782839           0.016448     0.105557\n",
      "75%      5.988367     5.984261     5.805869           0.065555     0.283272\n",
      "max      6.823417     6.913337     5.880104           0.170653     0.943313\n",
      "alpha = [0.01]\n",
      "       trhesholds  thresholds2  regressions  inner differences  differences\n",
      "count   10.000000    10.000000    10.000000          10.000000    10.000000\n",
      "mean    10.297690    10.284953    10.355418           0.164303     0.272470\n",
      "std      0.347537     0.283983     0.086159           0.144841     0.192394\n",
      "min      9.790609     9.858930    10.230873           0.000000     0.049531\n",
      "25%     10.071347    10.132058    10.311319           0.036824     0.149386\n",
      "50%     10.257128    10.236685    10.340686           0.154462     0.226644\n",
      "75%     10.526292    10.348932    10.422658           0.268987     0.384036\n",
      "max     10.910341    10.910341    10.481268           0.434292     0.683620\n"
     ]
    }
   ],
   "source": [
    "#Test \n",
    "nu = 32\n",
    "statistic = qt.tv_statistic\n",
    "# print(easy_cor_1N[0])\n",
    "\n",
    "tested = 10\n",
    "alpha = [0.5]\n",
    "values = np.zeros([tested, 3])\n",
    "for index in range(tested):\n",
    "    regressor = learner_5N\n",
    "    histogram = create_bins_combination(8)\n",
    "    tree = qt.QuantTree(histogram)\n",
    "    number = np.random.randint(10, 1000)\n",
    "    tree.ndata =number\n",
    "    rich_histogram = np.append(histogram, float(number))\n",
    "    # print(len(rich_histogram), easy_cor_1N.shape[1]) \n",
    "    threshold_computer = qt.ChangeDetectionTest(tree, nu, statistic)\n",
    "    threshold = threshold_computer.estimate_quanttree_threshold(alpha, 3000)\n",
    "    threshold2 = threshold_computer.estimate_quanttree_threshold(alpha, 3000)   \n",
    "    # rich_histogram = scaler.transform(rich_histogram.reshape(1, -1))\n",
    "    threshold3 = regressor.predict(rich_histogram.reshape(1, -1))\n",
    "    values[index] = np.array([ threshold, threshold2, threshold3])\n",
    "final_frame = pd.DataFrame(values)\n",
    "final_frame['inner differences'] = np.abs(values[:,0] - values[:,1])\n",
    "final_frame['differences'] = np.abs(values[:,0] - values[:,2])\n",
    "final_frame =  final_frame.rename(columns={0:'trhesholds', 1 : 'thresholds2', 2:'regressions' })\n",
    "print('alpha = '+str(alpha))\n",
    "print(final_frame.describe())\n",
    "\n",
    "tested = 10\n",
    "alpha = [0.01]\n",
    "values = np.zeros([tested, 3])\n",
    "for index in range(tested):\n",
    "    regressor = learner_1N\n",
    "    histogram = create_bins_combination(8)\n",
    "    tree = qt.QuantTree(histogram)\n",
    "    number = np.random.randint(10, 1000)\n",
    "    tree.ndata =number\n",
    "    rich_histogram = np.append(histogram, float(number))\n",
    "    # print(len(rich_histogram), easy_cor_1N.shape[1]) \n",
    "    threshold_computer = qt.ChangeDetectionTest(tree, nu, statistic)\n",
    "    threshold = threshold_computer.estimate_quanttree_threshold(alpha, 3000)\n",
    "    threshold2 = threshold_computer.estimate_quanttree_threshold(alpha, 3000)   \n",
    "    # rich_histogram = scaler.transform(rich_histogram.reshape(1, -1))\n",
    "    threshold3 = regressor.predict(rich_histogram.reshape(1, -1))\n",
    "    values[index] = np.array([ threshold, threshold2, threshold3])\n",
    "final_frame = pd.DataFrame(values)\n",
    "final_frame['inner differences'] = np.abs(values[:,0] - values[:,1])\n",
    "final_frame['differences'] = np.abs(values[:,0] - values[:,2])\n",
    "final_frame =  final_frame.rename(columns={0:'trhesholds', 1 : 'thresholds2', 2:'regressions' })\n",
    "print('alpha = '+str(alpha))\n",
    "print(final_frame.describe())\n",
    "#print ('r2 is ' + str(r2_score(final_frame['trhesholds'], final_frame['regressions'])))\n",
    "#print('inner r2 is ' + str(r2_score(final_frame['trhesholds'], final_frame['thresholds2'])))\n",
    "\n",
    "#Dictionary creation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle the trained net with the characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle: store\n",
    "\n",
    "dictionary = {('normal', 0.01): learner_1N, ('normal', 0.5): learner_5N,\n",
    "              ('asymptotic', 0.01): learner_1A, ('Asymptotic', 0.5): learner_5A}\n",
    "\n",
    "\n",
    "with open('network.pickle', 'wb') as handle:\n",
    "    pk.dump(dictionary, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=10, learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=10000,\n",
      "             momentum=0.9, n_iter_no_change=40, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=True, shuffle=True, solver='lbfgs',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([10.48126801])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pickle: verify it works\n",
    "\n",
    "file2 = open('network.pickle', 'rb')\n",
    "new_d = pk.load(file2)\n",
    "print(new_d[('normal', 0.01)])\n",
    "file2.close()\n",
    "new_d[('normal', 0.01)].predict(rich_histogram.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
