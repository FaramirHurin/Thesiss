{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import sklearn as sk\n",
    "\n",
    "sys.path.append('C:\\\\Users\\\\dalun\\\\PycharmProjects\\\\Thesiss')\n",
    "\n",
    "import qtLibrary.libquanttree as qt\n",
    "import main_code.neuralNetworks as nn\n",
    "import pickle as pk\n",
    "from main_code.auxiliary_project_functions import create_bins_combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16947259348224802\n",
      "0.06604053528243103\n",
      "0.07034939431321958\n",
      "0.08242142618464099\n"
     ]
    }
   ],
   "source": [
    "#Create dataframe from saved thresholds\n",
    "\n",
    "frame_1N = pd.read_csv('File_N_and_thr_0_01')\n",
    "frame_5N = pd.read_csv('File_N_and_thr_0_5')\n",
    "frame_1A = pd.read_csv('Asymptotic_0._1')\n",
    "frame_5A = pd.read_csv('Asymptotic_0_5')\n",
    "\n",
    "frames = [frame_1N, frame_1A, frame_5N, frame_5A]\n",
    "\n",
    "for frame in frames:\n",
    "    frame = frame.iloc[:, 1:]\n",
    "\n",
    "# frame_1N = frame_1N.iloc[:,1:]\n",
    "# frame_1A = frame_1A.iloc[:,1:]\n",
    "# frame_5N = frame_5N.iloc[:,1:]\n",
    "# frame_5A = frame_5A.iloc[:,1:]\n",
    "    \n",
    "\n",
    "training_1N = frame_1N.iloc[:, np.r_[:frame.shape[1] - 1, -1]]\n",
    "thresholds_1N = frame_1N.iloc[:,-2]\n",
    "\n",
    "training_5N = frame_5N.iloc[:, np.r_[:frame.shape[1] - 1, -1]]\n",
    "thresholds_5N = frame_5N.iloc[:,-2]\n",
    "\n",
    "training_1A = frame_1A.iloc[:, 1:-1]\n",
    "thresholds_1A = frame_1A.iloc[:,-1]\n",
    "\n",
    "training_5A = frame_5A.iloc[:, 1:-1]\n",
    "thresholds_5A = frame_5A.iloc[:,-1]\n",
    "    \n",
    "for threshold in [thresholds_1N, thresholds_5N, thresholds_1A, thresholds_5A]:\n",
    "    print(np.var(threshold))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 10\n",
      "0.4621412471968213\n",
      "0.18851229703268557\n",
      "0.1147419766566825\n",
      "0.0003459488000780997\n"
     ]
    }
   ],
   "source": [
    "#Train networks\n",
    "\n",
    "nodes = 10\n",
    "print('nodes: ' + str(nodes))\n",
    "easy_cor_1N = np.array(training_1N) #.iloc[:,-3:]\n",
    "easy_cor_5N = np.array(training_5N) #.iloc[:,-3:]\n",
    "easy_cor_1A = np.array(training_1A) #.iloc[:,-3:]\n",
    "easy_cor_5A = np.array(training_5A) #.iloc[:,-3:]\n",
    "\n",
    "\n",
    "easy_cor = [easy_cor_1N, easy_cor_5N, easy_cor_1A, easy_cor_5A]\n",
    "thresholds = [thresholds_1N, thresholds_5N, thresholds_1A, thresholds_5N]\n",
    "\n",
    "learner_1N = sk.neural_network.MLPRegressor(early_stopping=True, hidden_layer_sizes=nodes, solver='lbfgs', learning_rate='constant', max_iter=10000, n_iter_no_change=40, verbose=False, random_state=True, alpha = 0)\n",
    "learner_5N = sk.neural_network.MLPRegressor(early_stopping=True, hidden_layer_sizes=nodes, solver='lbfgs', learning_rate='constant', max_iter=10000, n_iter_no_change=40, verbose=False, random_state=True, alpha = 0)\n",
    "learner_1A = sk.neural_network.MLPRegressor(early_stopping=True, hidden_layer_sizes=nodes, solver='lbfgs', learning_rate='constant', max_iter=10000, n_iter_no_change=40, verbose=False, random_state=True, alpha = 0)\n",
    "learner_5A = sk.neural_network.MLPRegressor(early_stopping=True, hidden_layer_sizes=nodes, solver='lbfgs', learning_rate='constant', max_iter=10000, n_iter_no_change=40, verbose=False, random_state=True, alpha = 0)\n",
    "\n",
    "learners = [learner_1N, learner_5N, learner_1A, learner_5A]\n",
    "\n",
    "for index in range(len(learners)):\n",
    "    learners[index].fit(easy_cor[index], thresholds[index])\n",
    "    print(learners[index].score(easy_cor[index], thresholds[index]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = [0.5]\n",
      "       trhesholds  thresholds2  regressions  inner differences  differences\n",
      "count   10.000000    10.000000    10.000000          10.000000    10.000000\n",
      "mean     6.014363     6.030089     5.809328           0.041970     0.308812\n",
      "std      0.437716     0.433220     0.034859           0.041254     0.342290\n",
      "min      5.554043     5.630245     5.769475           0.000000     0.033280\n",
      "25%      5.730636     5.749687     5.782469           0.014774     0.051293\n",
      "50%      5.775417     5.791478     5.795172           0.032870     0.163243\n",
      "75%      6.341100     6.296440     5.842483           0.056242     0.540895\n",
      "max      6.786295     6.868905     5.858401           0.132836     0.952972\n",
      "alpha = [0.01]\n",
      "       trhesholds  thresholds2  regressions  inner differences  differences\n",
      "count   10.000000    10.000000    10.000000          10.000000    10.000000\n",
      "mean    10.151529    10.173365    10.323129           0.234276     0.273440\n",
      "std      0.228670     0.180329     0.066293           0.184789     0.154469\n",
      "min      9.867605     9.901006    10.213093           0.019459     0.077935\n",
      "25%      9.961175    10.054731    10.283528           0.069943     0.140328\n",
      "50%     10.109213    10.153014    10.314243           0.219747     0.248569\n",
      "75%     10.347428    10.267546    10.368581           0.346158     0.396971\n",
      "max     10.509437    10.493550    10.419716           0.530564     0.507489\n"
     ]
    }
   ],
   "source": [
    "#Test \n",
    "nu = 32\n",
    "statistic = qt.tv_statistic\n",
    "# print(easy_cor_1N[0])\n",
    "\n",
    "tested = 10\n",
    "alpha = [0.5]\n",
    "values = np.zeros([tested, 3])\n",
    "for index in range(tested):\n",
    "    regressor = learner_5N\n",
    "    histogram = create_bins_combination(8)\n",
    "    tree = qt.QuantTree(histogram)\n",
    "    number = np.random.randint(10, 1000)\n",
    "    tree.ndata =number\n",
    "    rich_histogram = np.append(histogram, float(number))\n",
    "    # print(len(rich_histogram), easy_cor_1N.shape[1]) \n",
    "    threshold_computer = qt.ChangeDetectionTest(tree, nu, statistic)\n",
    "    threshold = threshold_computer.estimate_quanttree_threshold(alpha, 3000)\n",
    "    threshold2 = threshold_computer.estimate_quanttree_threshold(alpha, 3000)   \n",
    "    # rich_histogram = scaler.transform(rich_histogram.reshape(1, -1))\n",
    "    threshold3 = regressor.predict(rich_histogram.reshape(1, -1))\n",
    "    values[index] = np.array([ threshold, threshold2, threshold3])\n",
    "final_frame = pd.DataFrame(values)\n",
    "final_frame['inner differences'] = np.abs(values[:,0] - values[:,1])\n",
    "final_frame['differences'] = np.abs(values[:,0] - values[:,2])\n",
    "final_frame =  final_frame.rename(columns={0:'trhesholds', 1 : 'thresholds2', 2:'regressions' })\n",
    "print('alpha = '+str(alpha))\n",
    "print(final_frame.describe())\n",
    "\n",
    "tested = 10\n",
    "alpha = [0.01]\n",
    "values = np.zeros([tested, 3])\n",
    "for index in range(tested):\n",
    "    regressor = learner_1N\n",
    "    histogram = create_bins_combination(8)\n",
    "    tree = qt.QuantTree(histogram)\n",
    "    number = np.random.randint(10, 1000)\n",
    "    tree.ndata =number\n",
    "    rich_histogram = np.append(histogram, float(number))\n",
    "    # print(len(rich_histogram), easy_cor_1N.shape[1]) \n",
    "    threshold_computer = qt.ChangeDetectionTest(tree, nu, statistic)\n",
    "    threshold = threshold_computer.estimate_quanttree_threshold(alpha, 3000)\n",
    "    threshold2 = threshold_computer.estimate_quanttree_threshold(alpha, 3000)   \n",
    "    # rich_histogram = scaler.transform(rich_histogram.reshape(1, -1))\n",
    "    threshold3 = regressor.predict(rich_histogram.reshape(1, -1))\n",
    "    values[index] = np.array([ threshold, threshold2, threshold3])\n",
    "final_frame = pd.DataFrame(values)\n",
    "final_frame['inner differences'] = np.abs(values[:,0] - values[:,1])\n",
    "final_frame['differences'] = np.abs(values[:,0] - values[:,2])\n",
    "final_frame =  final_frame.rename(columns={0:'trhesholds', 1 : 'thresholds2', 2:'regressions' })\n",
    "print('alpha = '+str(alpha))\n",
    "print(final_frame.describe())\n",
    "#print ('r2 is ' + str(r2_score(final_frame['trhesholds'], final_frame['regressions'])))\n",
    "#print('inner r2 is ' + str(r2_score(final_frame['trhesholds'], final_frame['thresholds2'])))\n",
    "\n",
    "#Dictionary creation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle the trained net with the characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle: store\n",
    "\n",
    "dictionary = {('normal', 0.01): learner_1N, ('normal', 0.5): learner_5N,\n",
    "              ('asymptotic', 0.01): learner_1A, ('Asymptotic', 0.5): learner_5A}\n",
    "\n",
    "\n",
    "with open('network.pickle', 'wb') as handle:\n",
    "    pk.dump(dictionary, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=10, learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=10000,\n",
      "             momentum=0.9, n_iter_no_change=40, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=True, shuffle=True, solver='lbfgs',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([10.35841553])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pickle: verify it works\n",
    "\n",
    "file2 = open('network.pickle', 'rb')\n",
    "new_d = pk.load(file2)\n",
    "print(new_d[('normal', 0.01)])\n",
    "file2.close()\n",
    "new_d[('normal', 0.01)].predict(rich_histogram.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
